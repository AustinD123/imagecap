{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67dfd61f-e736-484e-8e53-74a705887c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os as os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5fa9e5d-9843-4618-9e45-f6bb646e0002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82783, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"yerevann/coco-karpathy\")\n",
    "ds['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e27ccc9-a992-4f52-9e75-ae1fb1eb6c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7632, 102]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer.encode(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a7ae79-4c39-4eed-a263-fc79210b2256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filepath': 'train2014',\n",
       " 'sentids': [787980, 789366, 789888, 791316, 794853],\n",
       " 'filename': 'COCO_train2014_000000057870.jpg',\n",
       " 'imgid': 40504,\n",
       " 'split': 'train',\n",
       " 'sentences': ['A restaurant has modern wooden tables and chairs.',\n",
       "  'A long restaurant table with rattan rounded back chairs.',\n",
       "  'a long table with a plant on top of it surrounded with wooden chairs ',\n",
       "  'A long table with a flower arrangement in the middle for meetings',\n",
       "  'A table is adorned with wooden chairs with blue accents.'],\n",
       " 'cocoid': 57870,\n",
       " 'url': 'http://images.cocodataset.org/train2014/COCO_train2014_000000057870.jpg'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5856a5a-1491-4f46-92c3-de3cc1b3ce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torchvision.transforms as transforms\n",
    "from datasets import DatasetDict\n",
    "import logging\n",
    "import random\n",
    "\n",
    "class maindataset(Dataset):\n",
    "    def __init__(self,dataset,tokenizer,transforms):\n",
    "        self.dataset=dataset\n",
    "        self.tokenizer=tokenizer\n",
    "        self.transforms=transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item=self.dataset[index]\n",
    "        sentences=item['sentences']\n",
    "        text= random.choice(sentences)\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Process 'input_ids', 'attention_mask', etc.\n",
    "        input_ids = encoding['input_ids'].squeeze(0)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "        try:\n",
    "            response = requests.get(item['url'], stream=True, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "            img_tensor = self.transform(img)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error loading image from URL {item['url']}: {e}\")\n",
    "            img_tensor = torch.zeros(3, 224, 224)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'image': img_tensor,\n",
    "            'imgid': item['imgid'],\n",
    "            'cocoid': item.get('cocoid', -1),\n",
    "            'filename': item['filename'],\n",
    "            'filepath': item['filepath']\n",
    "        }\n",
    "    \n",
    "\n",
    "def create_dataloaders(dataset_dict, tokenizer_name=\"bert-base-uncased\", batch_size=32, \n",
    "                       num_workers=4, use_all_sentences=False):\n",
    "    \"\"\"\n",
    "    Create dataloaders using the predefined splits in the dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset_dict: HuggingFace DatasetDict containing the dataset splits\n",
    "        tokenizer_name: Name of the tokenizer to use\n",
    "        batch_size: Batch size for the dataloaders\n",
    "        num_workers: Number of workers for data loading\n",
    "        use_all_sentences: Whether to use all sentences or randomly select one\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing dataloaders for each split\n",
    "    \"\"\"\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    # Create image transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # Create datasets for each split\n",
    "    datasets = {}\n",
    "    dataloaders = {}\n",
    "    \n",
    "    for split, dataset in dataset_dict.items():\n",
    "        datasets[split] = maindataset(\n",
    "            dataset=dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            transform=transform,\n",
    "            use_all_sentences=use_all_sentences\n",
    "        )\n",
    "        \n",
    "        shuffle = (split == 'train' or split == 'restval')  # Shuffle for training and restval\n",
    "        \n",
    "        dataloaders[split] = DataLoader(\n",
    "            datasets[split],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True  # Helps speed up data transfer to GPU\n",
    "        )\n",
    "    \n",
    "    return dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adda015-6c27-425d-92fe-2bd52d4030ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
